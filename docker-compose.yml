services:

  postgres:
    container_name: postgres
    command:
      - "postgres"
      - "-c"
      - "log_destination=stderr" # Log to stderr so Docker can get it
      - "-c"
      - "logging_collector=on"
      - "-c"
      - "log_line_prefix=" # Clear the default prefix
      - "-c"
      - "log_statement=all"
      - "-c"
      - "log_min_messages=info"
      - "-c"
      - "log_min_error_statement=info"
      - "-c"
      - "log_timezone=UTC"
      # THIS IS THE MAGIC PART
      - "-c"
      - "log_destination=jsonlog"
    image: postgres
    env_file:
      - .env
    networks:
      - nuros
    restart: always
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - postgres-data:/var/lib/postgresql/data

  fastapi:
    container_name: fastapi
    build:
      context: .
      dockerfile: Dockerfile
      args:
        IS_DEBUG: ${IS_DEBUG:-true}  # Default to 'true' if not set
    networks:
      - nuros
    restart: always
    env_file:
      - .env
    volumes:
      - .:/nuros  # Sync local backend folder with container's /nuros
      - cursor-server:/root/.cursor-server
    depends_on:
      - postgres
    environment:
      - PYTHONUNBUFFERED=1
      - WORKERS=${GUNICORN_WORKERS:-4}


  nginx:
    container_name: nginx
    image: nginx:latest
    networks:
      - nuros
    restart: always
    ports:
      - "80:80"  # Expose Nginx on port 80 of localhost
    volumes:
      - ./backend/core/configs/nginx.dev.conf:/etc/nginx/nginx.conf
      - ./frontend/dist:/var/www/my-app/dist  # Make sure this folder exists in production builds
    depends_on:
      - fastapi
      - pgadmin
    command: [ "/bin/sh", "-c", "
      apt update && apt install -y inotify-tools &&
      (while inotifywait -e modify /etc/nginx/nginx.conf; do
        echo 'nginx config changed, copying and reloading Nginx...' &&
        nginx -t && nginx -s reload;
      done) &
      nginx -g 'daemon off;'
      " ]


  pgadmin:
      image: dpage/pgadmin4
      container_name: pgadmindev
      environment:
        PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
        PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
      depends_on:
        - postgres
      restart: always
      networks:
        - nuros
      volumes:
        - pgadmin-data:/var/lib/pgadmin  # Named volume for persistent data
        - ./backend/core/configs/pgadmin_config/servers.json:/pgadmin4/servers.json  # Auto-connect to PostgreSQL
        - ./backend/core/configs/pgadmin_config/pgpass:/pgpass  # Auto-login credentials


  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: cloudflared
    networks:
      - nuros
    restart: always
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARED_TOKEN}  # Each developer sets their token
    command: tunnel run
    depends_on:
      - nginx  # Ensure nginx is up before starting tunnel


  redis:
    image: redis:latest
    networks:
      - nuros
    container_name: redis
    restart: always
    volumes:
      - redis-data:/data
      - ./backend/core/configs/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server --bind 0.0.0.0 --protected-mode no

  meilisearch:
    image: getmeili/meilisearch:latest
    networks:
      - nuros
    container_name: meilisearch
    ports:
      - 7700:7700




  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    networks:
      - nuros
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-guest}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-guest}
      # RABBITMQ_LOGS: -
    ports:
      - "15672:15672"  # Management UI
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
      - ./backend/core/configs/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    healthcheck:
      test: ["CMD", "rabbitmq", "status"]
      interval: 30s
      timeout: 10s
      retries: 5


  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile_celery
    networks:
      - nuros
    env_file:
      - .env
    depends_on:
      - rabbitmq
      - redis
      - fastapi
    command: celery -A backend.celery_app.celery_config worker --loglevel=info -Q kick_queue,default
    environment:
      - CELERY_WORKER_CONCURRENCY=4  # Adjust based on your needs
      - CELERY_WORKER_PREFETCH_MULTIPLIER=1
    deploy:
      replicas: 2  # For scalability


  frontend:
    build:
      context: .
      dockerfile: Dockerfile_vite
    restart: always
    volumes:
      - ./frontend:/nuros           # Mount all project files
      - frontend-node-modules:/nuros/node_modules      # Use named volume for node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true  # Enable polling for file changes (Docker-friendly)
    networks:
      - nuros


networks:
  nuros:
    name: nuspace_nuros
    driver: bridge

volumes:
  postgres-data:
  redis-data:
    driver: local
  pgadmin-data:
  rabbitmq-data:  # Add this
  frontend-node-modules:  # Named volume for frontend node_modules
  cursor-server: